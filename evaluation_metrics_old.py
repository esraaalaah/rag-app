import pandas as pd
import evaluate

# 1. ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¯Ø§ØªØ§ Ù…Ù† Ù…Ù„Ù CSV
# ØªØ£ÙƒØ¯ÙŠ Ø¥Ù† Ø§Ù„Ù…Ù„Ù ÙÙŠ Ù†ÙØ³ ÙÙˆÙ„Ø¯Ø± Ø§Ù„Ù…Ø´Ø±ÙˆØ¹ Ø£Ùˆ Ø­Ø·ÙŠ Ø§Ù„Ù…Ø³Ø§Ø± Ø§Ù„ÙƒØ§Ù…Ù„
data = pd.read_csv("my_data.csv")

# 2. ØªØ¬Ù‡ÙŠØ² Ø§Ù„Ù…Ø±Ø¬Ø¹ ÙˆØ§Ù„ØªÙ†Ø¨Ø¤Ø§Øª Ù„ÙƒÙ„ Ù†Ø¸Ø§Ù…
references = data["reference"].tolist()

systems = {
    "RAG": data["rag_prediction"].tolist(),
    "DR-RAG": data["dr_rag_prediction"].tolist(),
    "DR-RAG+CAG": data["dr_rag_cag_prediction"].tolist(),
}

# 3. ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù‚Ø§ÙŠÙŠØ³
rouge = evaluate.load("rouge")
bleu = evaluate.load("bleu")
bertscore = evaluate.load("bertscore")

# 4. Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ù‚Ø§ÙŠÙŠØ³ Ù„ÙƒÙ„ Ù†Ø¸Ø§Ù…
results = {}

for system_name, predictions in systems.items():
    print(f"\nğŸ”¹ Evaluating {system_name}...")
    
    # ROUGE
    rouge_result = rouge.compute(predictions=predictions, references=references)
    
    # BLEU
    bleu_result = bleu.compute(predictions=predictions, references=references)
    
    # BERTScore
    bert_result = bertscore.compute(predictions=predictions, references=references, lang="en")
    avg_bert_f1 = sum(bert_result["f1"]) / len(bert_result["f1"])
    
    results[system_name] = {
        "ROUGE-1": rouge_result["rouge1"],
        "ROUGE-2": rouge_result["rouge2"],
        "ROUGE-L": rouge_result["rougeL"],
        "BLEU": bleu_result["bleu"],
        "BERTScore-F1": avg_bert_f1,
    }

# 5. Ø·Ø¨Ø§Ø¹Ø© Ø§Ù„Ù†ØªØ§Ø¦Ø¬
print("\n===== ğŸ“Š Final Evaluation Results =====")
for system, metrics in results.items():
    print(f"\nSystem: {system}")
    for metric, value in metrics.items():
        print(f"  {metric}: {value:.4f}")